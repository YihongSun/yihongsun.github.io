<head>
    <!-- 
        !!!!
        Begin: Delete the following code if you want to use the code of my homepage
        !!!! 
    -->
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-K8X4PKK8RX"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-K8X4PKK8RX');
        </script>
        <!-- Global site tag (gtag.js) - Google Analytics -->

    
        <!-- Default Statcounter code for Homepage https://yihongsun.github.io -->
        <script type="text/javascript">
        var sc_project=13016970; 
        var sc_invisible=1; 
        var sc_security="53c21ccf"; 
        </script>
        <script type="text/javascript"
        src="https://www.statcounter.com/counter/counter.js" async></script>
        <noscript><div class="statcounter"><a title="Web Analytics
        Made Easy - Statcounter" href="https://statcounter.com/"
        target="_blank"><img class="statcounter"
        src="https://c.statcounter.com/13016970/0/53c21ccf/1/"
        alt="Web Analytics Made Easy - Statcounter"
        referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
        <!-- End of Statcounter Code -->
    
    <!-- 
        !!!!
        End: Delete the above code if you want to use the code of my homepage
        !!!! 
    -->
    
        <title>Yihong Sun's Homepage</title>
        <meta name="author" content="Yihong Sun">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta property="og:title" content="Yihong Sun">
        <meta property="og:description" content="CS Ph.D. student at Cornell University">
        <meta property="og:image" content="https://yihongsun.github.io/files/me.jpg">
        <meta property="og:url" content="https://yihongsun.github.io/">
        <meta name="twitter:card" content="summary_large_image">
        <link rel="apple-touch-icon" sizes="180x180" href="files/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="files/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="files/favicon-16x16.png">
        <link rel="manifest" href="files/site.webmanifest">
        <link rel="stylesheet" href="style.css">
    
    </head>
    
    <div >
        <div class="content row">
            <div class="header-profile-picture"></div>
            <div class="header-text">
                <div class="header-name">
                    <h1>Yihong Sun</h1>
                </div>
                <div class="header-subtitle" style="font-size: 14px">
                    CS Ph.D. student at Cornell University
                </div>
                <div class="header-links" style="font-size: 14px">
                    <a class="btn" href="mailto:yihong@cs.cornell.edu">Email</a> /
                    <a class="btn" href="files/CV_Yihong_Sun.pdf">CV</a> /
                    <a class="btn" href="https://scholar.google.com/citations?user=JD2rFJEAAAAJ&hl=en">Google Scholar</a> /
                    <a class="btn" href="https://twitter.com/YihongSun_">Twitter</a> /
                    <a class="btn" href="https://github.com/YihongSun">GitHub</a> /
                    <a class="btn" href="https://www.linkedin.com/in/yihongsun/">LinkedIn</a> 
                </div>
                <div style="font-size: 14px">
                    <b>Contact</b>: yihong-AT-cs-DOT-cornell-DOT-edu
                </div>
            </div>
        </div>
    </div>
    <div class="content" style="padding-bottom: 64px;">
        <div>
            <h2 class="noselect">About Me</h2>
            <!-- <div style="border-top: 1px solid #000;"></div>
            <hr> -->
            <div style="font-size: 14px; line-height: 15pt;">
                I am a second-year CS PhD Student at <a href="https://www.cornell.edu/about/">Cornell University</a>, advised by Prof. <a href="https://www.cs.cornell.edu/~bharathh/">Bharath Hariharan</a>. 
                My work is supported by <a href="https://www.nsfgrfp.org/">NSF GRFP</a> and my research interests are computer vision and machine learning, especially in building vision algorithms that can learn from little supervision and generalize to unseen domains.
                <br/><br/>
                Previously, I obtained my Bachelor's degree from <a href="https://www.jhu.edu">Johns Hopkins University</a> where I studied Computer Science, Neuroscience, Applied Mathematics & Statistics, and Cognitive Science.
                During my undergradute studies, I worked with Bloomberg Distinguished Prof. <a href="http://www.cs.jhu.edu/~ayuille/">Alan Yuille</a> and Dr. <a href="https://generativevision.mpi-inf.mpg.de">Adam Kortylewski</a>.
                <br/><br/>
                If you would like to chat with me, please drop me an email! 
                <br/><br/>
            </div>
        </div>
    
        <div>
            <h2 class="noselect">Publications</h2>
            <!-- <p>(*) denotes equal contribution.</p> -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody class="publication_table">
                
            <script>
                function showPaperMessage(input_div_id) {
                    console.log(input_div_id);
                    // expand a message
                    status = document.getElementById(input_div_id).style.display;
                    console.log(status);
                    if (status != 'block')
                        document.getElementById(input_div_id).style.display = 'block';
                    else
                        document.getElementById(input_div_id).style.display = 'none'
      
                }
            </script>

            <!-- MOD-UV -->

            <tr >
                <td style="padding:7pt; width:32%; vertical-align:middle;">
                    <div class="one">
                        <div class="two" id="mod-uv_image" >
                        <img src="research/mod-uv.jpeg" width="100%">
                        </div>
                    </div>
                </td>
                
                <td style="padding-left: 7pt; padding-right:7pt; padding-top:12pt; padding-bottom:12pt; width:68%; vertical-align:middle; line-height: 18pt;">
                    <a href="https://github.com/YihongSun/MOD-UV">
                        <papertitle><strong>MOD-UV: Learning Mobile Object Detectors from Unlabeled Videos</strong></papertitle>
                    </a>
                    <div>
                    <strong>Yihong Sun</strong>,
                    <a href="https://www.cs.cornell.edu/~bharathh/">Bharath Hariharan</a>
                    </div>

                    <div>
                    <em>ECCV 2024</em>
                    </div>

                    <div id="paper_related">
                    <a href="https://arxiv.org/abs/2405.14841">Paper</a>
                    /
                    <a href="https://github.com/YihongSun/MOD-UV">Code</a>
                    </div>
                    
                    <div style="margin-top: 9pt">
                    We build an unsupervised mobile object detector from unlabeled videos only by leveraging independent motion information.
                    </div>
                </td>
            </tr>            

            <!-- Dymano-Depth -->
            
            <tr >
                <td style="padding:7pt; width:32%; vertical-align:middle">
                    <div class="one">
                        <div class="two" id="dynamo_image" >
                        <img src="research/dynamo-depth.jpeg" width="100%">
                        </div>
                    </div>
                </td>
                
                <td style="padding-left: 7pt; padding-right:7pt; padding-top:12pt; padding-bottom:12pt; width:68%; vertical-align:middle; line-height: 18pt;">
                    <a href="https://dynamo-depth.github.io/">
                        <papertitle><strong>Dynamo-Depth: Fixing Unsupervised Depth Estimation for Dynamical Scenes</strong></papertitle>
                    </a>
                    <div>
                    <strong>Yihong Sun</strong>,
                    <a href="https://www.cs.cornell.edu/~bharathh/">Bharath Hariharan</a>
                    </div>

                    <div>
                    <em>NeurIPS 2023</em>
                    </div>

                    <div id="paper_related">
                    <a href="https://arxiv.org/abs/2310.18887">Paper</a>
                    /
                    <a href="https://github.com/YihongSun/Dynamo-Depth">Code</a>
                    /
                    <a href="research/dynamo_poster.pdf">Poster</a>
                    /
                    <a href="https://dynamo-depth.github.io/">Project Page</a>
                    </div>
                    
                    <div style="margin-top: 9pt;">
                    We improve unsupervised monocular depth estimation for dynamical scenes by modeling 3D independent flow and motion segmentation.
                    </div>
                </td>
            </tr>            

            <!-- Bayesian-Amodal -->

            <tr >
                <td style="padding:7pt; width:32%; vertical-align:middle">
                    <div class="one">
                        <div class="two" id="amodal_image" >
                        <img src="research/bayesian-amodal.jpeg" width="100%">
                        </div>
                    </div>
                </td>
                
                <td style="padding-left: 7pt; padding-right:7pt; padding-top:12pt; padding-bottom:12pt; width:68%; vertical-align:middle; line-height: 18pt;">
                    <a href="https://github.com/YihongSun/Bayesian-Amodal">
                        <papertitle><strong>Amodal Segmentation through Out-of-Task and Out-of-Distribution Generalization with a Bayesian Model</strong></papertitle>
                    </a>
                    <div>
                    <strong>Yihong Sun</strong>,
                    <a href="https://generativevision.mpi-inf.mpg.de">Adam Kortylewski</a>,
                    <a href="http://www.cs.jhu.edu/~ayuille/">Alan Yuille</a>
                    </div>

                    <div>
                    <em>CVPR 2022</em>
                    </div>

                    <div id="paper_related">
                    <a href="https://arxiv.org/abs/2010.13175">Paper</a>
                    /
                    <a href="https://github.com/YihongSun/Bayesian-Amodal">Code</a>
                    /
                    <a href="research/amodal_poster.pdf">Poster</a>
                    /
                    <a href="research/amodal_supp.pdf">Supplementary</a>
                    </div>
                    
                    <div style="margin-top: 9pt;">
                    We tackle amodal segmentation using a Bayesian generative model trained from non-occluded images and box-level annotations only.
                    </div>
                </td>
            </tr>

            <!-- Occ-Reasoning -->

            <tr >
                <td style="padding:7pt; width:32%; vertical-align:middle">
                    <div class="one">
                        <div class="two" id="occ-reason_image" >
                        <img src="research/occ-reason.jpeg" width="100%">
                        </div>
                    </div>
                </td>
                
                <td style="padding-left: 7pt; padding-right:7pt; padding-top:12pt; padding-bottom:12pt; width:68%; vertical-align:middle; line-height: 18pt;">
                    <a href="https://github.com/XD7479/Multi-Object-Occlusion">
                        <papertitle><strong>Robust Instance Segmentation through Reasoning about Multi-Object Occlusion</strong></papertitle>
                    </a>
                    <div>
                    <a href="https://scholar.google.com/citations?user=p7QTY-cAAAAJ&hl=en">Xiaoding Yuan</a>,
                    <a href="https://generativevision.mpi-inf.mpg.de">Adam Kortylewski</a>,
                    <strong>Yihong Sun</strong>,
                    <a href="http://www.cs.jhu.edu/~ayuille/">Alan Yuille</a>
                    </div>

                    <div>
                    <em>CVPR 2021</em>
                    </div>

                    <div id="paper_related">
                    <a href="https://arxiv.org/abs/2012.02107">Paper</a>
                    /
                    <a href="https://github.com/XD7479/Multi-Object-Occlusion">Code</a>
                    </div>
                    
                    <div style="margin-top: 9pt;">
                    We reason about multi-object self-occlusions by inspecting part-level activations of a Bayesian generative model.
                    </div>
                </td>
            </tr>

            <!-- CompNet-Det -->

            <tr >
                <td style="padding:7pt; width:32%; vertical-align:middle">
                    <div class="one">
                        <div class="two" id="compnet-det_image" >
                        <img src="research/compnet-det.jpeg" width="100%">
                        </div>
                    </div>
                </td>
                
                <td style="padding-left: 7pt; padding-right:7pt; padding-top:12pt; padding-bottom:12pt; width:68%; vertical-align:middle; line-height: 18pt;">
                    <a href="https://arxiv.org/abs/2005.11643">
                        <papertitle><strong>Robust Object Detection Under Occlusion With Context-Aware CompositionalNets</strong></papertitle>
                    </a>
                    <div>
                    <a href="https://angtianwang.github.io">Angtian Wang(*)</a>,
                    <strong>Yihong Sun(*)</strong>,
                    <a href="https://generativevision.mpi-inf.mpg.de">Adam Kortylewski</a>,
                    <a href="http://www.cs.jhu.edu/~ayuille/">Alan Yuille</a>
                    </div>

                    <div>
                    <em>CVPR 2020</em>
                    </div>

                    <div id="paper_related">
                    <a href="https://arxiv.org/abs/2005.11643">Paper</a>
                    /
                    <a href="https://youtu.be/XalAhF8Bi_0">Video</a>
                    /
                    <a href="https://github.com/Angtian/OccludedPASCAL3D">Data</a>
                    
                    </div>

                    <div>
                    (*) indicates joint first authors
                    </div>
                    
                    <div style="margin-top: 9pt;">
                    We improve object detection under partial occlusion by regulating contextual bias and enhancing localization via compositional part voting.
                    </div>
                </td>
            </tr>

            <!-- CompNet -->

            <tr >
                <td style="padding:7pt; width:32%; vertical-align:middle">
                    <div class="one">
                        <div class="two" id="compnet_image" >
                        <img src="research/compnet.jpeg" width="100%">
                        </div>
                    </div>
                </td>
                
                <td style="padding-left: 7pt; padding-right:7pt; padding-top:12pt; padding-bottom:12pt; width:68%; vertical-align:middle; line-height: 18pt;">
                    <a href="https://arxiv.org/abs/2006.15538">
                        <papertitle><strong>Compositional Convolutional Neural Networks: A Robust and Interpretable Model for Object Recognition under Occlusion</strong></papertitle>
                    </a>
                    <div>
                    <a href="https://generativevision.mpi-inf.mpg.de">Adam Kortylewski</a>,
                    <a href="https://qliu24.github.io">Qing Liu</a>,
                    <a href="https://angtianwang.github.io">Angtian Wang</a>,
                    <strong>Yihong Sun</strong>,
                    <a href="http://www.cs.jhu.edu/~ayuille/">Alan Yuille</a>
                    </div>

                    <div>
                    <em>IJCV 2020</em>
                    </div>

                    <div id="paper_related">
                    <a href="https://arxiv.org/abs/2006.15538">Paper</a>
                    /
                    <a href="https://github.com/AdamKortylewski/CompositionalNets">Code</a>
                    </div>
                    
                    <div style="margin-top: 9pt;">
                    We propose CompositionalNets, interpretable deep architectures with innate robustness to partial occlusion, for image classification and object detection.
                    </div>
                </td>
            </tr>
      
            </tbody>
            </table>
        </div>

        <div>
            <h2 class="noselect">Teaching</h2>
            <!-- <p>(*) denotes equal contribution.</p> -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody class="publication_table">
                
            <script>
                function showPaperMessage(input_div_id) {
                    console.log(input_div_id);
                    // expand a message
                    status = document.getElementById(input_div_id).style.display;
                    console.log(status);
                    if (status != 'block')
                        document.getElementById(input_div_id).style.display = 'block';
                    else
                        document.getElementById(input_div_id).style.display = 'none'
      
                }
            </script>

            <!-- Cornell -->

            <tr >
                <td style="padding:10pt; width:36%; vertical-align:middle">
                    <div class="one">
                        <div class="two" id="cornell_image" >
                        <img src="files/cornell.png" width="100%">
                        </div>
                    </div>
                </td>
                
                <td style="padding-left: 7pt; padding-right:7pt; padding-top:12pt; padding-bottom:12pt; width:68%; vertical-align:middle; line-height: 18pt;">
                    <papertitle><strong>Graduate Teaching Assistant</strong></papertitle>
                    <div>
                        Bowers CIS College of Computing and Information Science
                    </div>
                    
                    <div style="margin-top: 9pt;">
                        - CS4670/5670 Introduction to Computer Vision (<a href="https://www.cs.cornell.edu/courses/cs4670/2021sp/"><em>SP23</em></a>)
                    </div>
                    <div style="margin-top: 1pt;">
                        - CS4787/5777 Principles of Large-Scale Machine Learning (<a href="https://www.cs.cornell.edu/courses/cs4787/2022fa/"><em>FA22</em></a>)
                    </div>

                </td>
            </tr>            

            <!-- JHU -->
            
            <tr >
                <td style="padding:30pt; width:36%; vertical-align:middle">
                    <div class="one">
                        <div class="two" id="jhu_image" >
                        <img src="files/jhu.png" width="100%">
                        </div>
                    </div>
                </td>
                
                <td style="padding-left: 7pt; padding-right:7pt; padding-top:12pt; padding-bottom:12pt; width:68%; vertical-align:middle; line-height: 18pt;">
                    <papertitle><strong>Undergraduate Course Assistant</strong></papertitle>
                    <div>
                        Department of Computer Science
                    </div>
                    
                    <div style="margin-top: 9pt;">
                        - EN.601.783 Vision as Bayesian Inference (<a href="https://www.cs.jhu.edu/~ayuille/JHUcourses/VisionAsBayesianInference2022/601.783.html"><em>SP22</em></a>)
                    </div>
                    <div style="margin-top: 1pt;">
                        - AS.050.375/675 Probabilistic Models of the Visual Cortex (<a href="http://www.cs.jhu.edu/~ayuille/JHUcourses/ProbabilisticModelsOfVisualCognition2021/ProbModelsIndex.html"><em>FA21</em></a>, <a href="http://www.cs.jhu.edu/~ayuille/JHUcourses/ProbabilisticModelsOfVisualCognition2020/ProbModelsIndex.html"><em>FA20</em></a>)
                    </div>
                    <div style="margin-top: 1pt;">
                        - EN.601.226 Data Structures (<a href="https://cs226sp21.github.io/index.html"><em>SP21</em></a>, <a href="https://cs226fall20.github.io/"><em>FA20</em></a>, <a href="https://cs226sp20.github.io/"><em>SP20</em></a>)
                    </div>

                </td>
            </tr>      

      
            </tbody>
            </table>
        </div>        
    
    </div>
    <div class="footer noselect">
        <div class="footer-content">
            &copy; 2024 Yihong Sun. Last updated: Jul., 2024. Website template from Nicklas Hansen and Haian Jin.
        </div>
    </div>
